






<!doctype html>
<html lang="">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="author" content="Hearrywang">
  
  
  
  
    <meta name="description" content="早期文本模型简介TF-IDF文本模型
1983年提出，是基于信息论中著名的TF-IDF公式来对文本进行建模的。TF-IDF公式的计算是对两个部分进行乘积，第一个部分称为词频部分（即TF部分），用来表示文本中某个词在该文本中出现的频率，计算上是用该词在该文本中出现的次数除以该文本包含的词的个数；第二个部分称为逆文本部分（即IDF部分），用来表示在语料库中有多少篇文本包含了这个词，计算上是用总文...">
  
  <title>学习记录 [ Blog ]</title>
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
  <link rel="stylesheet" href="/css/random.css">
<link rel="stylesheet" href="/css/vegas.min.css">
<link rel="stylesheet" href="/css/highlight-railscasts.css">
<link rel="stylesheet" href="/css/jquery.fancybox.css">
<link rel="stylesheet" href="/css/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/jquery.fancybox-thumbs.css">
<link rel="stylesheet" href="/css/plyr.css">
  
</head>

<body>
<div class="side-navigate hide-area">
  
    <div class="item prev">
      <a href="/2018/10/19/pageRank学习/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        pageRank学习
      </div>
    </div>
  
  
    <div class="item next">
      <a href="/2018/10/14/recomandWebSite/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        recomandWebSite
      </div>
    </div>
  
</div>
<div id="outer-container" class="hide-area">
<div id="container">
  <div id="menu-outer" class="slide-down">
    <div id="menu-inner">
      <div id="brand">
        
        <a onClick="openUserCard()">
          <img id="avatar" src="/head.jpg"/>
          <div id="homelink">Blog</div>
        </a>
      </div>
      <div id="menu-list">
        <ul>
        
        
          
            <li>
          
            <a href="/">Home</a>
            
          </li>
        
          
            <li>
          
            <a href="/archives">Archives</a>
            
          </li>
        
          
            <li>
          
            <a href="/tags">Tags</a>
            
          </li>
        
          
            <li>
          
            <a href="/categories">Categories</a>
            
          </li>
        
          
            <li>
          
            <a href="/about">About</a>
            
          </li>
        
          
            <li>
          
            <a href="https://github.com/Hearrywang">Github</a>
            
          </li>
        
        </ul>
      </div>
      <div id="show-menu">
        <button>Menu</button>
      </div>
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      
      
  <article id="post">
    <h1>学习记录</h1>
    <p class="page-title-sub">
      <span id = "post-title-date">Created at 2018-10-15</span>
      
        <span id = "post-title-updated">Updated at 2018-10-25</span>
      
      
      <span id = "post-title-categories">Category
      
      
        
        
        <a href="/categories/自然语言处理/">自然语言处理</a>
      
      </span>
      
      
      <span id = "post-title-tags">
      Tag
      
      
        
        
        <a href="/tags/文本模型/">文本模型</a>
      
      </span>
      
    </p>
    
    <h1 id="早期文本模型简介"><a href="#早期文本模型简介" class="headerlink" title="早期文本模型简介"></a>早期文本模型简介</h1><h3 id="TF-IDF文本模型"><a href="#TF-IDF文本模型" class="headerlink" title="TF-IDF文本模型"></a>TF-IDF文本模型</h3><ul>
<li>1983年提出，是基于信息论中著名的TF-IDF公式来对文本进行建模的。TF-IDF公式的计算是对两个部分进行乘积，第一个部分称为词频部分（即TF部分），用来表示文本中某个词在该文本中出现的频率，计算上是用该词在该文本中出现的次数除以该文本包含的词的个数；第二个部分称为逆文本部分（即IDF部分），用来表示在语料库中有多少篇文本包含了这个词，计算上是用总文本数除于含该词的文本数再取对数</li>
<li>计算好每个词的tf-idf值之后，我们就可以对目标语料库进行建模了。假设语料库中有N篇文档，M个不同的词，那么我们就可以建立一个M * N的矩阵，每一列代表一篇文档，每一行代表某个词在这篇文档中对应的tf-idf值，到此建模就完成啦。我们发现无论每篇包含多少个词，这样建模后每篇文档都被表示成了一个同样长度的向量，向量的每个值就是对应词的tf-idf值。建模矩阵如下图所示：<br><div align="center"><img src="1.png" alt="TF-IDF">        </div></li>
</ul>
<h3 id="向量空间模型-Vector-Space-Model"><a href="#向量空间模型-Vector-Space-Model" class="headerlink" title="向量空间模型(Vector Space Model)"></a>向量空间模型(Vector Space Model)</h3><ul>
<li>向量空间模型把文本内容简化处理为向量空间中的向量运算并以空间上的相似度表达语义的相似度。<ul>
<li>文档(Document): 泛指一般的文本</li>
<li>项(Term):    文档的内容特征常常用它所含有的基本语言单位来表示、文档可以用项集表示为D(T1,T2,…,Tn)</li>
<li>项的权重: 项常常被赋予一定的权重表示他们在文本D中的重要程度</li>
<li>向量空间模型(VSM):由于在文本中既可以重复出现又应该有先后次序的关系,分析起来有一定困难。为了简化分析,暂时不考虑的顺序,并要求互异,这时文档D就可以被看作是一个n维向量了</li>
</ul>
</li>
<li>对向量空间模型来说，有两个基本问题：即特征项的选择和项的权重计算</li>
<li>特征项选择<ul>
<li>文本中存在一些没有实在意义但使用频率很高的虚词和功能词        禁用词表 or 进行权重计算时,使它们的权重很低,通过取阀值将它们丢弃        提取形容词、动词和名词作为特征项,并尝试着取代禁用词表方法</li>
<li>采用词语作为特征项时还会出现所谓的同义现象    例如电脑和计算机是同一个概念,应该属于同一个特征项,目前最常用的解决方案是采用概念词典来解决这个问题</li>
</ul>
</li>
<li><p>分词 (好多种方法)</p>
<ul>
<li>基于字符串匹配的分词方法 (1) 最大匹配法 (2) 逆向最大匹配法 (3) 逐词遍历匹配法 (4) 双向扫描法 (5) 最佳匹配法 (6) 设立切分标记法 (7) 有穷多级列举法</li>
<li>基于理解的分词方法</li>
<li>基于统计的分词方法 (1) 基于词频统计的切词法 (2) 基于期望的切词法</li>
</ul>
</li>
<li><p>特征值抽取<br>  *特征项选择一般使用统计方法,利用各种计算公式,计算词代表的信息含量,确定一个阀值,将低于阀值的词语过滤掉。或者确定一个特征项数目n,保留处于信息含量在前n位的词条</p>
</li>
<li><p>特征提取评估函数</p>
<ul>
<li>文档频数(document frequency)</li>
<li>信息增益(information gain)</li>
<li>期望交叉熵(expected cross entropy)</li>
<li>互信息(mutual information)</li>
</ul>
</li>
</ul>
<p>###奇异值分解(SVD)<br>    <em><div align="center"><img src="2.png" alt="TF-IDF">    
    </div></em><div align="center"><img src="3.png" alt="TF-IDF"><br>    *注上图中等号右边的左右矩阵分别代表在同一个语义空间不同document之间的相关性和同意语义空间不同term之间的相关性。中间矩阵则是语义空间中的正交基。</div></p>
<h3 id="LSI文本模型"><a href="#LSI文本模型" class="headerlink" title="LSI文本模型"></a>LSI文本模型</h3><ul>
<li><p>LSA(latent semantic analysis)潜在语义分析，也被称为LSI(latent semantic index) 该方法和传统向量空间模型(vector space model)一样使用向量来表示词(terms)和文档(documents)，并通过向量间的关系(如夹角)来判断词及文档间的关系；而不同的是，LSA将词和文档映射到潜在语义空间，从而去除了原始向量空间中的一些“噪音”，提高了信息检索的精确度。LSA的基本思想就是把高维的文档降到低维空间，那个空间被称为潜在语义空间。这个映射必须是严格线性的而且是基于共现表（就是那个矩阵啦）的奇异值分解</p>
<ul>
<li>LDA好文    </li>
<li><a href="https://zhuanlan.zhihu.com/p/29932017" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29932017</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/46617465" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46617465</a></li>
<li><a href="https://blog.csdn.net/pipisorry/article/details/42649657" target="_blank" rel="noopener">https://blog.csdn.net/pipisorry/article/details/42649657</a></li>
<li><p><a href="https://zhuanlan.zhihu.com/p/24555092" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24555092</a></p>
</li>
<li><p>[翻译整理]STACKOVERFLOW PYTHON 百问: <a href="http://www.wklken.me/posts/2013/07/20/python-stackoverflow-vote-top.html" target="_blank" rel="noopener">http://www.wklken.me/posts/2013/07/20/python-stackoverflow-vote-top.html</a></p>
</li>
</ul>
</li>
</ul>
<h3 id="LDA知乎详解-赞赞赞-https-zhuanlan-zhihu-com-p-31470216"><a href="#LDA知乎详解-赞赞赞-https-zhuanlan-zhihu-com-p-31470216" class="headerlink" title="LDA知乎详解 赞赞赞 https://zhuanlan.zhihu.com/p/31470216"></a>LDA知乎详解 赞赞赞 <a href="https://zhuanlan.zhihu.com/p/31470216" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31470216</a></h3>
  </article>
  <div class="random-toc-area">
  <button class="btn-hide-toc btn-hide-toc-show" style="display: none" onclick="TOCToggle()">Show TOC</button>
  <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">Hide TOC</button>
  <div class="random-toc">
    <h2>Table of Content</h2>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#早期文本模型简介"><span class="toc-text">早期文本模型简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#TF-IDF文本模型"><span class="toc-text">TF-IDF文本模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#向量空间模型-Vector-Space-Model"><span class="toc-text">向量空间模型(Vector Space Model)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LSI文本模型"><span class="toc-text">LSI文本模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LDA知乎详解-赞赞赞-https-zhuanlan-zhihu-com-p-31470216"><span class="toc-text">LDA知乎详解 赞赞赞 https://zhuanlan.zhihu.com/p/31470216</span></a></li></ol></li></ol></li></ol>
  </div>
</div>

  
<nav id="pagination">
  
    <a href="/2018/10/19/pageRank学习/" class="prev">&larr; Prev post pageRank学习</a>
  

  

  
    <a href="/2018/10/14/recomandWebSite/" class="next">Next post recomandWebSite &rarr;</a>
  
</nav>

  <!-- JiaThis Button BEGIN -->

<!-- JiaThis Button END -->


      
      
    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      Site by Hearrywang using
      <a href="http://hexo.io">Hexo</a> & <a href="https://github.com/stiekel/hexo-theme-random">Random</a>
      <br>
      
    </div>
  </div>
</div>

</div>


<div id="user-card">
  <div class="center-field">
    <img class="avatar" src="/head.jpg">
    <p id="description"></p>
    <ul class="social-icon">
  
  
    <li>
      <a href="https://github.com/Hearrywang">
        
          <i class="icon iconfont github">&#xe606;</i>
        
      </a>
    </li>
  
    <li>
      <a href="null">
        
          Coding.NET
        
      </a>
    </li>
  
    <li>
      <a href="null">
        
          Twitter
        
      </a>
    </li>
  
    <li>
      <a href="https://weibo.com/3759016451/profile?topnav=1&wvr=6">
        
          <i class="icon iconfont weibo">&#xe602;</i>
        
      </a>
    </li>
  
    <li>
      <a href="null">
        
          DouBan
        
      </a>
    </li>
  
</ul>
  </div>
</div>


<script>
// is trigger analytics / tongji script
var isIgnoreHost = false;

if(window && window.location && window.location.host) {
  isIgnoreHost = ["localhost","127.0.0.1"].some(function(address){
    return 0 === window.location.host.indexOf(address);
  });
}

var isTriggerAnalytics = !( true && isIgnoreHost );

</script>




  
  
    <script src="/js/jquery-2.2.3.min.js"></script>
  
    <script src="/js/vegas.min.js"></script>
  
    <script src="/js/random.js"></script>
  
    <script src="/js/highlight.pack.js"></script>
  
    <script src="/js/jquery.mousewheel.pack.js"></script>
  
    <script src="/js/jquery.fancybox.pack.js"></script>
  
    <script src="/js/jquery.fancybox-thumbs.js"></script>
  
    <script src="/js/plyr.js"></script>
  

<script>

  // fancybox
  var backgroundImages = [];
  
  $('#post').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox') || $(this).parent().hasClass('fancybox-thumb')) return;
      var alt = this.alt || this.title;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'post' + i);
    });
  });
  $(".fancybox").fancybox();

var vegasConfig = {"preload­Image":true,"transition":["slideLeft2","slideRight2","flash2"],"timer":true,"delay":5000,"shuffle":true,"count":28};
var unsplashConfig = {"gravity":"north"};
// is show background images
var turnoffBackgroundImage = false;



  turnoffBackgroundImage = true;


var backgroundColor = "34495E";

$(".fancybox-thumb").fancybox({
  prevEffect: 'none',
  nextEffect: 'none',
  helpers: {
    title: {
      type: 'outside'
    },
    thumbs: {
      width: 50,
      height: 50
    }
  }
});

// show video with plyr
$(".video-container iframe").each(function(i){
  var url = $(this).attr('src');
  var id = url.split('/').pop();
  var plyrContainer = document.createElement('div');
  plyrContainer.className = 'plyr';
  var plyrElement = document.createElement('div');
  plyrElement.dataset.videoId = id;
  switch(true) {
    case url.search('youtube.com') >= 0:
      plyrElement.dataset.type = 'youtube';
      break;
    case url.search('vimeo.com') >= 0:
      plyrElement.dataset.type = 'vimeo';
      break;
    default:
      return;
  };
  plyrContainer.appendChild(plyrElement);
  $(this).parent().html(plyrContainer);
});
plyr.setup('.plyr', {iconUrl: '/css/sprite.svg'});
</script>
</body>
</html>

